{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a3d7a368",
   "metadata": {},
   "source": [
    "# TITANIC CON MACHINE LEARNING\n",
    "\n",
    "#### Descarga deL DataSet:\n",
    "https://www.kaggle.com/datasets/vinicius150987/titanic3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bead030",
   "metadata": {},
   "source": [
    "## Visualizacion del DataSet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aa6097a",
   "metadata": {},
   "source": [
    "### Lectura del DataSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "10201d16",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/Titanic/titanic3.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Lectura del DataSet mediante funciones de Python.\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/Titanic/titanic3.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m train_set:\n\u001b[1;32m      3\u001b[0m     df \u001b[38;5;241m=\u001b[39m train_set\u001b[38;5;241m.\u001b[39mreadlines()\n\u001b[1;32m      4\u001b[0m df\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/IPython/core/interactiveshell.py:286\u001b[0m, in \u001b[0;36m_modified_open\u001b[0;34m(file, *args, **kwargs)\u001b[0m\n\u001b[1;32m    279\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[1;32m    280\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    281\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    282\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    283\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    284\u001b[0m     )\n\u001b[0;32m--> 286\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m io_open(file, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/Titanic/titanic3.csv'"
     ]
    }
   ],
   "source": [
    "# Lectura del DataSet mediante funciones de Python.\n",
    "with open (\"Titanic/titanic3.csv\") as train_set:\n",
    "    df = train_set.readlines()\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c722859d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Passengers</th>\n",
       "      <th>pclass</th>\n",
       "      <th>survived</th>\n",
       "      <th>name</th>\n",
       "      <th>length_name</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>ticket</th>\n",
       "      <th>fare</th>\n",
       "      <th>cabin</th>\n",
       "      <th>embarked</th>\n",
       "      <th>boat</th>\n",
       "      <th>body</th>\n",
       "      <th>home.dest</th>\n",
       "      <th>person_rate</th>\n",
       "      <th>Characteristic_of_Number _Name</th>\n",
       "      <th>Name_Length</th>\n",
       "      <th>Age_group</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Allen, Miss. Elisabeth Walton</td>\n",
       "      <td>29</td>\n",
       "      <td>female</td>\n",
       "      <td>29.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>24160</td>\n",
       "      <td>211.3375</td>\n",
       "      <td>B5</td>\n",
       "      <td>S</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>St Louis, MO</td>\n",
       "      <td>211.3375</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>Adulto Joven</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Allison, Master. Hudson Trevor</td>\n",
       "      <td>30</td>\n",
       "      <td>male</td>\n",
       "      <td>0.9167</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>113781</td>\n",
       "      <td>151.5500</td>\n",
       "      <td>C22 C26</td>\n",
       "      <td>S</td>\n",
       "      <td>11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Montreal, PQ / Chesterville, ON</td>\n",
       "      <td>37.8875</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>Niño</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Allison, Miss. Helen Loraine</td>\n",
       "      <td>28</td>\n",
       "      <td>female</td>\n",
       "      <td>2.0000</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>113781</td>\n",
       "      <td>151.5500</td>\n",
       "      <td>C22 C26</td>\n",
       "      <td>S</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Montreal, PQ / Chesterville, ON</td>\n",
       "      <td>37.8875</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>Niño</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Allison, Mr. Hudson Joshua Creighton</td>\n",
       "      <td>36</td>\n",
       "      <td>male</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>113781</td>\n",
       "      <td>151.5500</td>\n",
       "      <td>C22 C26</td>\n",
       "      <td>S</td>\n",
       "      <td>NaN</td>\n",
       "      <td>135.0</td>\n",
       "      <td>Montreal, PQ / Chesterville, ON</td>\n",
       "      <td>37.8875</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>Adulto Joven</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Allison, Mrs. Hudson J C (Bessie Waldo Daniels)</td>\n",
       "      <td>47</td>\n",
       "      <td>female</td>\n",
       "      <td>25.0000</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>113781</td>\n",
       "      <td>151.5500</td>\n",
       "      <td>C22 C26</td>\n",
       "      <td>S</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Montreal, PQ / Chesterville, ON</td>\n",
       "      <td>37.8875</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>Adulto Joven</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1304</th>\n",
       "      <td>1305</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>Zabour, Miss. Hileni</td>\n",
       "      <td>20</td>\n",
       "      <td>female</td>\n",
       "      <td>14.5000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2665</td>\n",
       "      <td>14.4542</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C</td>\n",
       "      <td>NaN</td>\n",
       "      <td>328.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.2271</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Adolescente</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1305</th>\n",
       "      <td>1306</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>Zabour, Miss. Thamine</td>\n",
       "      <td>21</td>\n",
       "      <td>female</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2665</td>\n",
       "      <td>14.4542</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.2271</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Niño</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1306</th>\n",
       "      <td>1307</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>Zakarian, Mr. Mapriededer</td>\n",
       "      <td>25</td>\n",
       "      <td>male</td>\n",
       "      <td>26.5000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2656</td>\n",
       "      <td>7.2250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C</td>\n",
       "      <td>NaN</td>\n",
       "      <td>304.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.2250</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Adulto Joven</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1307</th>\n",
       "      <td>1308</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>Zakarian, Mr. Ortin</td>\n",
       "      <td>19</td>\n",
       "      <td>male</td>\n",
       "      <td>27.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2670</td>\n",
       "      <td>7.2250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.2250</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Adulto Joven</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1308</th>\n",
       "      <td>1309</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>Zimmerman, Mr. Leo</td>\n",
       "      <td>18</td>\n",
       "      <td>male</td>\n",
       "      <td>29.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>315082</td>\n",
       "      <td>7.8750</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.8750</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Adulto Joven</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1309 rows × 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Passengers  pclass  survived  \\\n",
       "0              1       1         1   \n",
       "1              2       1         1   \n",
       "2              3       1         0   \n",
       "3              4       1         0   \n",
       "4              5       1         0   \n",
       "...          ...     ...       ...   \n",
       "1304        1305       3         0   \n",
       "1305        1306       3         0   \n",
       "1306        1307       3         0   \n",
       "1307        1308       3         0   \n",
       "1308        1309       3         0   \n",
       "\n",
       "                                                 name  length_name     sex  \\\n",
       "0                       Allen, Miss. Elisabeth Walton           29  female   \n",
       "1                      Allison, Master. Hudson Trevor           30    male   \n",
       "2                        Allison, Miss. Helen Loraine           28  female   \n",
       "3                Allison, Mr. Hudson Joshua Creighton           36    male   \n",
       "4     Allison, Mrs. Hudson J C (Bessie Waldo Daniels)           47  female   \n",
       "...                                               ...          ...     ...   \n",
       "1304                             Zabour, Miss. Hileni           20  female   \n",
       "1305                            Zabour, Miss. Thamine           21  female   \n",
       "1306                        Zakarian, Mr. Mapriededer           25    male   \n",
       "1307                              Zakarian, Mr. Ortin           19    male   \n",
       "1308                               Zimmerman, Mr. Leo           18    male   \n",
       "\n",
       "          age  sibsp  parch  ticket      fare    cabin embarked boat   body  \\\n",
       "0     29.0000      0      0   24160  211.3375       B5        S    2    NaN   \n",
       "1      0.9167      1      2  113781  151.5500  C22 C26        S   11    NaN   \n",
       "2      2.0000      1      2  113781  151.5500  C22 C26        S  NaN    NaN   \n",
       "3     30.0000      1      2  113781  151.5500  C22 C26        S  NaN  135.0   \n",
       "4     25.0000      1      2  113781  151.5500  C22 C26        S  NaN    NaN   \n",
       "...       ...    ...    ...     ...       ...      ...      ...  ...    ...   \n",
       "1304  14.5000      1      0    2665   14.4542      NaN        C  NaN  328.0   \n",
       "1305      NaN      1      0    2665   14.4542      NaN        C  NaN    NaN   \n",
       "1306  26.5000      0      0    2656    7.2250      NaN        C  NaN  304.0   \n",
       "1307  27.0000      0      0    2670    7.2250      NaN        C  NaN    NaN   \n",
       "1308  29.0000      0      0  315082    7.8750      NaN        S  NaN    NaN   \n",
       "\n",
       "                            home.dest  person_rate  \\\n",
       "0                        St Louis, MO     211.3375   \n",
       "1     Montreal, PQ / Chesterville, ON      37.8875   \n",
       "2     Montreal, PQ / Chesterville, ON      37.8875   \n",
       "3     Montreal, PQ / Chesterville, ON      37.8875   \n",
       "4     Montreal, PQ / Chesterville, ON      37.8875   \n",
       "...                               ...          ...   \n",
       "1304                              NaN       7.2271   \n",
       "1305                              NaN       7.2271   \n",
       "1306                              NaN       7.2250   \n",
       "1307                              NaN       7.2250   \n",
       "1308                              NaN       7.8750   \n",
       "\n",
       "      Characteristic_of_Number _Name  Name_Length     Age_group  \n",
       "0                                  1            4  Adulto Joven  \n",
       "1                                  1            4          Niño  \n",
       "2                                  0            4          Niño  \n",
       "3                                  0            5  Adulto Joven  \n",
       "4                                  0            8  Adulto Joven  \n",
       "...                              ...          ...           ...  \n",
       "1304                               0            3   Adolescente  \n",
       "1305                               0            3          Niño  \n",
       "1306                               0            3  Adulto Joven  \n",
       "1307                               0            3  Adulto Joven  \n",
       "1308                               0            3  Adulto Joven  \n",
       "\n",
       "[1309 rows x 20 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lectura del DataSet utilizando Pandas\n",
    "import pandas as pd\n",
    "df = pd.read_csv(\"titanic3.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b6d50f60",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'Titanic/'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Mostrar los ficheros en el directorio del DataSet\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m os\u001b[38;5;241m.\u001b[39mlistdir(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTitanic/\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'Titanic/'"
     ]
    }
   ],
   "source": [
    "# Mostrar los ficheros en el directorio del DataSet\n",
    "import os\n",
    "\n",
    "os.listdir(\"Titanic/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "852bae3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instalar un paquete dentro de Jumpyter Notebook para parsear ficheros ARFF.\n",
    "\n",
    "import sys\n",
    "\n",
    "!{sys.executable} -m pip install liac-arff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a828c5b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"Titanic/titanic3.csv\")\n",
    "\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9627c9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtener únicamente los nombres de los atributos\n",
    "atributos = df.columns.tolist()\n",
    "print(atributos)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5216584",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"sex\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be32fe45",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"age\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1cc5bc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "atributos_manuales = [\"Passengers\", \"pclass\", \"survived\", \"name\", \"length_name\", \"sex\", \"age\", \"sibsp\", \"parch\", \"ticket\", \"fare\", \"cabin\", \"embarked\", \"boat\", \"body\", \"home.dest\", \"person rate\", \"Characteristic of Number Name\", \"Name\", \"Name Length\", \"Age group\"]\n",
    "\n",
    "print(atributos_manuales)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35106eec",
   "metadata": {},
   "source": [
    "## Funciones Básicas de visualizacion de los datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9f9c8f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def load_titanic_dataset(data_path):\n",
    "    \"\"\"Carga el conjunto de datos del Titanic desde un archivo CSV y devuelve un DataFrame de pandas.\"\"\"\n",
    "    df = pd.read_csv(data_path)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2f98090",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = 'Titanic/titanic3.csv'\n",
    "df_titanic = load_titanic_dataset(data_path)\n",
    "\n",
    "print(df_titanic)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5dd49cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lectura y copia del DataSet\n",
    "df_orig = load_titanic_dataset('Titanic/titanic3.csv')\n",
    "df = df_orig.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72ae7b55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mostrar en pantalla un número determinado de filas.\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb465887",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mostrar informacion básica sobre el DataSet\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60da42c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mostrar información estadística sobre el DataSet.\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62bb7e91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mostrar los valores únicos que tenga un atributo determinado.\n",
    "df[\"person_rate\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65adcd0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mostrar los valores de la caracteristica como un histograma.\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "df[\"person_rate\"].hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d29aba9",
   "metadata": {},
   "source": [
    "## Funciones avanzadas de visualización de los datos. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2b94e19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# El atributo class de nuestro conjunto de datos tiene valores categoricos.\n",
    "df[\"person_rate\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "656f5b93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformar los valores del atributo class de categoricos a númericos.\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "labelencoder = LabelEncoder()\n",
    "df[\"person_rate\"] = labelencoder.fit_transform(df[\"person_rate\"])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "024d889b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Mostrar la correlacion entre los atributos del conjunto de datos.\n",
    "corr_matrix = df.corr(numeric_only=True)\n",
    "corr_matrix[\"person_rate\"].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56a1c285",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mostrar correlacion lineal entre todos los atributos del DataSet\n",
    "df.corr(numeric_only=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4e16983",
   "metadata": {},
   "source": [
    "### Matriz de correlación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f92462d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#representar graficamente la matriz correlacion.\n",
    "corr = df.corr(numeric_only=True)\n",
    "fig, ax = plt.subplots(figsize=(8, 8))\n",
    "ax.matshow(corr)\n",
    "plt.xticks(range(len(corr.columns)), corr.columns);\n",
    "plt.yticks(range(len(corr.columns)), corr.columns);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3b53b99",
   "metadata": {},
   "source": [
    "# Preparación Del DataSet\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d47b1284",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f3d7005",
   "metadata": {},
   "outputs": [],
   "source": [
    "import arff\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c46c492a",
   "metadata": {},
   "source": [
    "## Funciones Auxiliares."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18c21ceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def load_titanic_dataset_csv(data_path):\n",
    "    \"\"\"Lectura del conjunto de datos Titanic en formato CSV.\"\"\"\n",
    "    return pd.read_csv(data_path)\n",
    "\n",
    "def titanic_train_val_test_split(df, rstate=42, shuffle=True, stratify=None):\n",
    "    strat = df[stratify] if stratify else None\n",
    "    train_set, test_set = train_test_split(\n",
    "        df, test_size=0.3, random_state=rstate, shuffle=shuffle, stratify=strat\n",
    "    )\n",
    "    strat = test_set[stratify] if stratify else None\n",
    "    val_set, test_set = train_test_split(\n",
    "        test_set, test_size=0.5, random_state=rstate, shuffle=shuffle, stratify=strat\n",
    "    )\n",
    "    return train_set, val_set, test_set\n",
    "\n",
    "# Cargar el conjunto de datos del Titanic\n",
    "df = load_titanic_dataset_csv(\"Titanic/titanic3.csv\")\n",
    "\n",
    "# Dividir el conjunto de datos en entrenamiento, validación y prueba sin estratificación\n",
    "train_set, val_set, test_set = titanic_train_val_test_split(df, stratify=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ee117dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = load_titanic_dataset_csv(\"Titanic/titanic3.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaa383b7",
   "metadata": {},
   "source": [
    "# Preparación del DataSet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ea4190e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print (\"Longitud del Trainig Set: \", len(train_set))\n",
    "print (\"Longitud del Validation Set: \", len(val_set))\n",
    "print (\"Longitud del Test Set: \", len(test_set))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16567ebd",
   "metadata": {},
   "source": [
    "## Limpiando Datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d49b2a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separar las características de entrada de las características de salida.\n",
    "X_train = train_set.drop(\"survived\", axis=1)\n",
    "y_train = train_set[\"survived\"].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f634f15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Para ilustrarlo es necesario añadir algunos valores nulos.\n",
    "# a algunas características del DataSet.\n",
    "X_train.loc[X_train[\"age\"] > 25, \"age\"] = np.nan\n",
    "X_train.loc[X_train[\"fare\"] < 20, \"fare\"] = np.nan\n",
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05ffa7fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comprobar si existe algun atributo con valores nulos.\n",
    "X_train.isna().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e683f0d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seleccionar las filas que contengan valores nulos.\n",
    "filas_valores_nulos = X_train[X_train.isnull().any(axis= 1)]\n",
    "filas_valores_nulos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "973846bd",
   "metadata": {},
   "source": [
    "## Rellenar los valores nulos con imputer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d6746e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copiar el DataSet para no alterar el original \n",
    "X_train_copy = X_train.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2938312",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "imputer = SimpleImputer(strategy = \"median\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0d48d58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# La clase Imputer no admite valores categoricos, se elimina los atributos categoricos.\n",
    "X_train_copy_num = X_train_copy.select_dtypes(exclude = ['object'])\n",
    "X_train_copy_num.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ccb4959",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se le proporcionan los atributos numéricos para que calcule los valores\n",
    "imputer.fit(X_train_copy_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "127509d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_copy_num_nonan = imputer.transform(X_train_copy_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a258445",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rellenar los valores nulos.\n",
    "X_train_copy_num = pd.DataFrame(X_train_copy_num_nonan, columns = X_train_copy_num.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f343f99a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_copy.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fe3eef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_set.drop(\"survived\", axis=1)\n",
    "y_train = train_set[\"survived\"].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "639a8622",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4cc7536",
   "metadata": {},
   "outputs": [],
   "source": [
    "sex = X_train['sex']\n",
    "sex_encoded, categories = sex.factorize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f497746",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mostrar como se codificarón.\n",
    "for i in range(10):\n",
    "    print(sex.iloc[i], \"=\", sex_encoded[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4436d654",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(categories)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55593372",
   "metadata": {},
   "source": [
    "## Transformaciones avanzadas mediante Sklearn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9f42a83",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "\n",
    "sex_column = X_train[['sex']]\n",
    "\n",
    "ordinal_encoder = OrdinalEncoder()\n",
    "sex_encoded = ordinal_encoder.fit_transform(sex_column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb465036",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mostrar cómo se han modificado las categorías.\n",
    "for i in range(10):\n",
    "    print(sex_column[\"sex\"].iloc[i], \"=\", sex_encoded[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18b5df25",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(categories)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87c79f25",
   "metadata": {},
   "source": [
    "#### One-Hot encoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4237c5fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "sex_column = X_train[['sex']]\n",
    "\n",
    "oh_encoder = OneHotEncoder()\n",
    "sex_oh = oh_encoder.fit_transform(sex_column)\n",
    "sex_oh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3169b8ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "sex_oh_array = sex_oh.toarray()\n",
    "sex_oh_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91fe114e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mostrar por pantalla cómo se han codificado\n",
    "for i in range(10):\n",
    "    print(sex_column[\"sex\"].iloc[i], \"=\", sex_oh_array[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0215844",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ordinal_encoder.categories_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cca37a21",
   "metadata": {},
   "outputs": [],
   "source": [
    "oh_encoder = OneHotEncoder(handle_unknown = 'ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "420f3c09",
   "metadata": {},
   "source": [
    "### Get Dummies "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a331ec8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Realizar la codificación one-hot de la columna 'sex'\n",
    "sex_oh = pd.get_dummies(X_train['sex'])\n",
    "\n",
    "# Mostrar por pantalla cómo se han codificado\n",
    "print(sex_oh.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad17d6f4",
   "metadata": {},
   "source": [
    "## Escalado del DataSet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21d775bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seleccionar características de entrada\n",
    "X_train = df[['pclass', 'age', 'sex', 'fare', 'sibsp']]\n",
    "\n",
    "# Seleccionar columna de salida\n",
    "y_train = df['survived'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00576700",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import RobustScaler\n",
    "\n",
    "# Supongamos que queremos escalar las características 'age' y 'fare'\n",
    "scale_attrs = X_train[['age', 'fare']]\n",
    "\n",
    "# Inicializar el RobustScaler\n",
    "robust_scaler = RobustScaler()\n",
    "\n",
    "# Aplicar la transformación de escala\n",
    "X_train_scaled = robust_scaler.fit_transform(scale_attrs)\n",
    "\n",
    "# Crear un DataFrame con las características escaladas\n",
    "X_train_scaled = pd.DataFrame(X_train_scaled, columns=['age', 'fare'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "158e92d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_scaled.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5ebf82b",
   "metadata": {},
   "source": [
    "# Evaluacion de Resultados.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "465f263f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_titanic_dataset_csv(data_path):\n",
    "    \"\"\"Lectura del conjunto de datos Titanic en formato CSV.\"\"\"\n",
    "    return pd.read_csv(data_path)\n",
    "\n",
    "# Utiliza la función load_titanic_dataset_csv para cargar el conjunto de datos del Titanic en formato CSV\n",
    "df_titanic = load_titanic_dataset_csv(\"Titanic/titanic3.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c81ad6e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68863367",
   "metadata": {},
   "source": [
    "## División del DataSet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "063878a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dividir el conjunto de datos en entrenamiento y prueba (60% entrenamiento, 20% prueba)\n",
    "train_set, test_set = train_test_split(df, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e78bc0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d112c8b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e158fe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Separar el conjunto de datos de pruebas 50% validation set, 50% test_set.\n",
    "val_set, test_set = train_test_split(test_set, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f4bd3be",
   "metadata": {},
   "outputs": [],
   "source": [
    "print (\"Longitud del Trainig Set: \", len(train_set))\n",
    "print (\"Longitud del Validation Set: \", len(val_set))\n",
    "print (\"Longitud del Test Set: \", len(test_set))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04c9ee76",
   "metadata": {},
   "source": [
    "# Particionado aleatorio y Stratified Sampling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b55c74c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Si shuffle=false, el DataSet no mezclará antes del particionado.\n",
    "train_set, test_set = train_test_split(df, test_size=0.2, random_state=42, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bebb73e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set, test_set = train_test_split(df, test_size=0.2, random_state=42, stratify=df[\"survived\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ecc80e1",
   "metadata": {},
   "source": [
    "## Generación de una Funcion de Particionado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75f41f7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construcción de una función de particionado que realice el particionado completo.\n",
    "def train_val_test_split(df, rstate=42, shuffle=True, stratify=None):\n",
    "    strat = df[stratify] if stratify else None\n",
    "    train_set, test_set = train_test_split(\n",
    "    df, test_size=0.4, random_state=rstate, shuffle=shuffle, stratify=strat)\n",
    "    strat = test_set[stratify] if stratify else None\n",
    "    val_set, test_set = train_test_split(\n",
    "    test_set, test_size=0.5, random_state=rstate, shuffle=shuffle, stratify=strat)\n",
    "    return(train_set, val_set, test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b45243c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Longitud del conjunto del DataSet: \", len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2905f700",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set, val_set, test_set = train_val_test_split(df, stratify='survived')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fc2a642",
   "metadata": {},
   "outputs": [],
   "source": [
    "print (\"Longitud del Trainig Set: \", len(train_set))\n",
    "print (\"Longitud del Validation Set: \", len(val_set))\n",
    "print (\"Longitud del Test Set: \", len(test_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daf65670",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comprobar que stratify mantiene la proporcion de la característica en \n",
    "# los subconjuntos.\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "df[\"survived\"].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5256b418",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_set[\"survived\"].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4edd58e",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_set[\"survived\"].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23e1e42d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import arff\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.base import BaseEstimator, TransformerMixin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad518713",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_titanic_dataset_csv(data_path):\n",
    "    \"\"\"Lectura del conjunto de datos Titanic en formato CSV.\"\"\"\n",
    "    return pd.read_csv(data_path)\n",
    "\n",
    "# Cargar el conjunto de datos del Titanic\n",
    "df = load_titanic_dataset_csv(\"Titanic/titanic3.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dfc1c70",
   "metadata": {},
   "outputs": [],
   "source": [
    "def titanic_train_val_test_split(df, rstate=42, shuffle=True, stratify=None):\n",
    "    strat = df[stratify] if stratify else None\n",
    "    train_set, test_set = train_test_split(\n",
    "        df, test_size=0.2, random_state=rstate, shuffle=shuffle, stratify=strat\n",
    "    )\n",
    "    strat = test_set[stratify] if stratify else None\n",
    "    val_set, test_set = train_test_split(\n",
    "        test_set, test_size=0.2, random_state=rstate, shuffle=shuffle, stratify=strat\n",
    "    )\n",
    "    return train_set, val_set, test_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "debee41e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construcción de un pipeline para los atributos numéricos\n",
    "num_pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('rbst_scaler', RobustScaler()),\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a45cd76",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomOneHotEncoder(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        self._oh = OneHotEncoder(sparse=None)\n",
    "        self._columns = None\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        X_cat = X.select_dtypes(include=['object'])\n",
    "        self._oh.fit(X_cat)\n",
    "        self._columns = self._get_feature_names_out(X_cat.columns)\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        X_copy = X.copy()\n",
    "        X_cat = X_copy.select_dtypes(include=['object'])\n",
    "        X_cat_oh = self._oh.transform(X_cat)\n",
    "        X_cat_oh = pd.DataFrame(X_cat_oh, columns=self._columns, index=X_copy.index)\n",
    "        X_copy.drop(list(X_cat), axis=1, inplace=True)\n",
    "        return X_copy.join(X_cat_oh)\n",
    "\n",
    "    def _get_feature_names_out(self, input_features=None):\n",
    "        if hasattr(self._oh, 'get_feature_names_out'):\n",
    "            return self._oh.get_feature_names_out(input_features)\n",
    "        else:\n",
    "            return self._oh.get_feature_names(input_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8334b498",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformador que prepara todo el conjunto de datos\n",
    "class DataFramePrepare(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        self._full_pipeline = None\n",
    "        self._columns = None\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        num_attribs = list(X.select_dtypes(exclude=['object']))\n",
    "        cat_attribs = list(X.select_dtypes(include=['object']))\n",
    "        \n",
    "        # Pipeline completo con transformadores personalizados\n",
    "        self._full_pipeline = ColumnTransformer([\n",
    "            (\"num\", num_pipeline, num_attribs),\n",
    "            (\"cat\", CustomOneHotEncoder(), cat_attribs),\n",
    "        ])\n",
    "        self._full_pipeline.fit(X)\n",
    "        self._columns = pd.get_dummies(X).columns\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X, y=None):\n",
    "        X_copy = X.copy()\n",
    "        X_prep = self._full_pipeline.transform(X_copy)\n",
    "        return pd.DataFrame(X_prep, columns=self._columns, index=X_copy.index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba01de88",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = load_titanic_dataset_csv(\"Titanic/titanic3.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa9f1181",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2d969d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# División del conjunto de datos en los diferentes subconjuntos\n",
    "train_set, val_set, test_set = train_val_test_split(df, stratify='survived')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "503d3eb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Longitud del Training Set: \", len(train_set))\n",
    "print(\"Longitud de Validacion del Set: \", len(val_set))\n",
    "print(\"Longitud del Test Set: \", len(test_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24f6ef98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conjunto de datos general\n",
    "X_df = df.drop(\"survived\", axis=1)\n",
    "y_df = df[\"survived\"].copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e00b9654",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conjunto de datos de entrenamiento\n",
    "X_train = train_set.drop(\"survived\", axis=1)\n",
    "y_train = train_set[\"survived\"].copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0dc9f16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conjunto de validación\n",
    "X_val = val_set.drop(\"survived\", axis=1)\n",
    "y_val = val_set[\"survived\"].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f55bd210",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conjunto de pruebas\n",
    "X_test = test_set.drop(\"survived\", axis=1)\n",
    "y_test = test_set[\"survived\"].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02fe77bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instanciar el transformador personalizado\n",
    "data_preparer = DataFramePrepare()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e034656",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# Asegúrate de usar sparse_output=False si necesitas una matriz densa (NumPy)\n",
    "encoder = OneHotEncoder(sparse_output=False)\n",
    "\n",
    "# Ajusta el encoder y transforma los datos\n",
    "X_encoded = encoder.fit_transform(X_df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc810173",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5db79bde",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "\n",
    "# Supongamos que X_train es tu conjunto de datos original\n",
    "# Selecciona solo las columnas numéricas\n",
    "numeric_columns = X_train.select_dtypes(include=['float64', 'int64']).columns\n",
    "\n",
    "# Inicializa el StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Aplica el scaler solo a las columnas numéricas y guárdalas en X_train_prep\n",
    "X_train_prep = X_train.copy()  # crea una copia para no modificar X_train original\n",
    "X_train_prep[numeric_columns] = scaler.fit_transform(X_train[numeric_columns])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f8570d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_prep.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2c4369a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Codificación One-Hot para variables categóricas\n",
    "X_train_encoded = pd.get_dummies(X_train)\n",
    "\n",
    "# Llenar valores nulos con la media\n",
    "X_train_encoded_filled = X_train_encoded.fillna(X_train_encoded.mean())\n",
    "\n",
    "# Entrenamiento del modelo de regresión logística\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "clf = LogisticRegression(max_iter=600)\n",
    "clf.fit(X_train_encoded_filled, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df193c54",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_csv('Titanic/titanic3.csv')\n",
    "\n",
    "X = data.drop('survived', axis=1)\n",
    "y = data['survived']\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "numeric_cols = ['length_name', 'age', 'sibsp', 'parch', 'fare', 'person_rate', 'Characteristic_of_Number _Name', 'Name_Length']\n",
    "categorical_cols = ['pclass', 'sex', 'embarked', 'Age_group']\n",
    "\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='mean')),  \n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),  \n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_cols),\n",
    "        ('cat', categorical_transformer, categorical_cols)\n",
    "    ])\n",
    "\n",
    "clf = LogisticRegression(max_iter=600)\n",
    "\n",
    "\n",
    "pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                             ('classifier', clf)])\n",
    "\n",
    "\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "y_pred = pipeline.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a168cc51",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val_preprocessed = preprocessor.transform(X_val)\n",
    "\n",
    "\n",
    "y_pred = pipeline.predict(X_val)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66fa28ab",
   "metadata": {},
   "source": [
    "### Matriz de confusion "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e28480d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Transforma los datos de validación\n",
    "X_val_preprocessed = preprocessor.transform(X_val)\n",
    "\n",
    "# Genera predicciones usando tu pipeline\n",
    "y_pred = pipeline.predict(X_val)\n",
    "\n",
    "# Crea y muestra la matriz de confusión\n",
    "disp = ConfusionMatrixDisplay.from_predictions(\n",
    "    y_val, y_pred, values_format='d', cmap=plt.cm.Blues\n",
    ")\n",
    "disp.ax_.set_title('Confusion Matrix')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf14be3b",
   "metadata": {},
   "source": [
    "# METRICAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd3fc46b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score\n",
    "\n",
    "y_pred = pipeline.predict(X_val)\n",
    "\n",
    "precision = precision_score(y_val, y_pred, pos_label=1)\n",
    "\n",
    "print(\"Precisión:\", precision)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e9ab765",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import recall_score\n",
    "\n",
    "y_pred = pipeline.predict(X_val)\n",
    "\n",
    "\n",
    "recall = recall_score(y_val, y_pred, pos_label=1)\n",
    "\n",
    "print(\"Recall:\", recall)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b21082e7",
   "metadata": {},
   "source": [
    "# F1 SCORE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7b22e2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "\n",
    "y_pred = pipeline.predict(X_val)\n",
    "\n",
    "\n",
    "f1 = f1_score(y_val, y_pred, pos_label=1)\n",
    "\n",
    "print(\"F1 Score:\", f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c154d9f1",
   "metadata": {},
   "source": [
    "## 3.- Curvas ROC Y PR."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46cc88fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import RocCurveDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Genera las probabilidades para la clase positiva (asumiendo un problema binario)\n",
    "y_pred_prob = pipeline.predict_proba(X_val)[:, 1]\n",
    "\n",
    "# Crea y muestra la curva ROC\n",
    "RocCurveDisplay.from_predictions(y_val, y_pred_prob)\n",
    "plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec0c4337",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import PrecisionRecallDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Genera las probabilidades para la clase positiva (asumiendo un problema binario)\n",
    "y_pred_prob = pipeline.predict_proba(X_val)[:, 1]\n",
    "\n",
    "# Crea y muestra la curva Precision-Recall\n",
    "PrecisionRecallDisplay.from_predictions(y_val, y_pred_prob)\n",
    "plt.title('Precision-Recall Curve')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bf58a38",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e0cd643",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
